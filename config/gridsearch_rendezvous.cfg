# Config file for grid search 

# Use semi-colon to define new scenario.
# All inputs will be combined when running grid search algorithm.

############################################################################
# Neural Network Related Configurations
############################################################################

# Gridsearch type
# GRIDSEARCH_FULL_SCAN, GRIDSEARCH_RANDOM, GRIDSEARCH_HILL_CLIMB

EXECUTABLE						=	bin/RLFramework

# Redirect stdout 
# Redirect executable outputs to another console or file. 
# tty command should be queried.
# Example: ">/dev/pts/112"
# Example: ">/dev/tty4"

# REDIRECTION						=	

# Environment selection
# gridworld, blocksworld, rendezvous

ENVIRONMENT						=	rendezvous

# Agent selection
# deep-q-network, greedy-agent, online-trajectory-value-iteration, q-iteration, trajectory-based-value-iteration

AGENT							=	trajectory-based-value-iteration

# Representation selection
# FunctionApproximatorNeuralNetwork, RepresentationDeepQNetworkUDP, RepresentationUDP, TabularStateActionPair, RepresentationActorCriticTabular

REPRESENTATION					=	RepresentationUDP

# Config for Executable
# An config file chosen from config folder.

CONFIG							=	config/config_rendezvous_5x5_1agent.cfg

# Gridsearch type
# GRIDSEARCH_FULL_SCAN, GRIDSEARCH_RANDOM, GRIDSEARCH_HILL_CLIMB

GRIDSEARCH_TYPE					=	GRIDSEARCH_FULL_SCAN

EPSILON_PROBABILITY				=   0.2

EPSILON_PROBABILITY_DECAYRATE	=   1.0

HIDDEN_LAYERS					=	64;64

CRITIC_HIDDEN_LAYERS			=	32;32

EXPERIENCE_REPLAY_BUFFER		= 	256

BATCH_SIZE						=   32

TRAINING_PASS_PER_BATCH			= 	1

LENGTH_OF_TRAJECTORY			=   64

# DEEP_ALGO_TYPE
# DeepQNetwork_PrioritizedReplay, DeepActorCritic_PrioritizedReplay 

DEEP_ALGO_TYPE					=   DeepActorCritic_PrioritizedReplay